第12章 内存管理
	在内核里分配内存不像在其他地方分配内存那么容易.
	造成这种局面的因素很多.从根本上讲,是因为内核本身不能像用户空间那样奢侈地使用内存.
	内核与用户空间不同,它不具备这种能力,它不支持简单便携的内存分配方式.比如,内核一般
	不能睡眠.此外,处理内存分配错误对内核来说也绝非易事.

	不过,从程序开发角度来看,也不是说内核的内存分配就困难得不得了,只是和用户空间中的
	内存分配不太一样而已.

	本章讨论的是在内核之中获得内存的方法.在深入研究实际分配接口之前,我们需要理解内核
	是如何管理内存的.


12.1 页
	内核把物理页作为内存管理的基本单元.
	尽管处理器的最小可寻址单位通常为字
	,但是,内存管理单元(MMU,管理内存并把虚拟地址转换为物理地址的硬件)
	通常以页为单位来进行处理.正因为如此,MMU以页(page)大小为单位来管理系统中的页表
	(这也是页表的来由)从虚拟内存的角度来看,页就是最小单位.

	在第19章中我们将会看到,体系结构不同,支持的页大小也不尽相同,还有些体系结构支持几种
	不同的页大小.大多数32位体系结构支持4KB的页,而64位体系结构一般会支持8KB的页.这就
	意味着,在支持4KB页大小并有1GB物理内存的机器上.物理内存会被划分为262144个页.

	内核用struct page结构表示系统中的每个物理页,位于linux/mm_types.h中
	去除了两个容易混淆我们讨论主题联合结构体:

	struct page {
		unsigned long flags;
		atomic_t      _count;
		atomic_t      _mapcount;
		unsigned long private;
		struct address_space *mapping;
		pgoff_t       index;
		struct list_head     lru;
		void             *virtual;
	}
	让我们看一下其中比较重要的
	
	域.flag域用来存放页的状态.这些状态包括页是不是脏的.
	是不是被锁定在内存中等.flag的每一位单独表示一种状态.

	_count域存放页的引用计数----也就是这一页被引用了多少次.
	当计数值变为-1时,就说明当前内核并没有引用这一页,于是,在新的分配中就可以使用它.
	内核代码不应当直接检查该域,而是调用page_count()函数进行检查,该函数唯一的参数就是
	page结构.
	当页空闲时,尽管该结构内部的__count值是负的.但是对page_count()函数而言,返回0
	表示页空闲返回一个正整数表示页在使用.

	一个页可以由缓存使用,或者作为私有数据,或者作为进程页表中的映射.

	virtual域是页的虚拟地址.通常情况下,它就是页在虚拟内存中的地址.有些内存
	(即所谓的高端内存)并不永久地映射到内核地址空间上.在这种情况下,这个域的值为NULL,
	需要的时候,必须动态地映射这些页

	必须要理解的一点是page结构与物理页相关而非虚拟页相关.因此,该结构对页的描述只是
	短暂的.内核仅仅用这个数据结构来描述当前时刻在相关的物理页中存放的东西.

	这种数据结构的目的在于描述物理内存本身,而不是描述包含在其中的数据.

	内核用这一结构来管理系统中所有的页,因为内核需要知道一个页是否空闲.如果页已经被
	分配,内核还需要知道谁拥有这个页.拥有者可能是用户空间进程,动态分配内核数据,静态
	内核代码或高速缓存

12.2 区
		由于硬件的限制,内核并不能对所有的页一视同仁.有些页位于内存中特定的物理地址上,
		所以不能将其一些特定的任务.由于存在这限制,所以内核把页划分为不同的区(zone)

	内存寻址错误:
		*一些硬件只能用某些特定的内存地址来执行DMA
		*一些体系结构的内存的物理寻址范围比虚拟寻址范围大得多,这样就有一些内存不能永久
		地映射到内核空间上
		因为存在这些制约条件,Linux主要使用四种区:
		*ZONE_DMA  ----这个区包含的页能用来执行DMA操作.
		*ZONE_DMA32
		*ZONE_NORMAL
		*ZONE_HIGHEM   这个区包含"高端内存",其中的页并不能永久地映射到内核地址空间.
		这些区(还有两种不大重要的)
	区的实际使用和分布是与体系结构相关的,例如,某些体系结构在内存的任何地址上执行DMA
	都没有问题.
	区的分配是与体系结构相关的.例如,某些


	Linux把系统的页划分为区,形成不同的内存池,这样就可以根据用途进行分配了.例如用途
	进行分配了.例如,ZONE_DMA内存池让内核有能力为DMA分配所需的内存.

	如果需要这样的内存,那么内核就可以从ZONE_NORMAL中进行分配,但是一般用途的内存既能
	从ZONE_DMA中分配,也能从ZONE_NORMAL中分配,不过不能同时从两个区分配,因为分配是不能
	跨区界限的.当然,内核更希望一般用途的内存从常规区分配,这样能节省ZONE_DMA中的页,
	保证满足DMA的使用需求.但是,如果可以供分配的资源不够用了,那么,内核就会去占用其他
	可用区的内存.

		不是所有的体系结构都定义了全部区,所有的物理内存都处于ZONE_DMA和ZONE_NORMAL.
		struct zone
		这个结构很大,但是,系统中只有三个区,因此,也只有三个这样的结构.让我们看一下其中
		一些重要的域.

		lock域是一个自旋转锁
		watermark数组持有该区的最小值,最低和最高水位值.
		name域是一个以NULL结束的字符串表示这个区的名字,内核启动期间初始化这个值,其代码
		位于mm/page_alloc.c中,三个区的名字分别为"DMA" "Normal" "HighMem"

12.3获得页
  我们已经对内核如何管理内存有所了解了,现在让我们看一下内核实现的接口,我们正是通过这些
  接口在内核内分配和释放内存的.
  内核提供了一种请求内存的底层机制,并提供了对它进行访问的几个接口.所有这些接口都以页为
  基本单位定义于linux/gfp.h中.最核心的函数是:
  struct page *alloc_pages(gfp_mask, unsigned int order)
	(分配2的 order次方的物理页 1<<order)连续的物理页
	并返回一个指针,该指针指向第一个页的page结构体:如果出错,就返回NULL

	void *page_address(struct page *page)
	该函数返回一个指针,指向给定物理页当前所在的逻辑地址.如果你无须用到struct page
	你可以调用:unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
	这个函数与alloc_pages()作用相同,不过它直接返回所请求的第一个页的逻辑地址.


	如果你只需要一页,就可以用下面两个封装好的函数,
	struct page *alloc_pages(gfp_t gfp_mas)
	unsigned long __get_free_page(gfp_t gfp_mask)
	这两个函数与其兄弟函数工作方式相同,只不过传给给order的值为0

	12.3.1获得填充为0的页
		如果你需要让返回的页的内容全为0,请用下面这个函数:
		unsigned long get_zeroed_page(unsigned int gfp_mask)
	表12.2是所有底层页分配方法的列表

12.3.2 释放页
	当你不再需要页时,可以用下面的函数释放它们:
	void __free_pages(struct page *page, unsigned int order)
	void free_pages(unsigned long addr, unsigned int order)
	void free_pages(unsigned long addr)
	释放页时要谨慎,只能释放属于你的页.传递了错误的struct page或地址,用了错误order值
	这些 可能导致系统崩溃.请记住,内核是完全信赖自己的,这点和用户空间不同,
	如果你有非法操作,内核会开开心把自己挂起来,停止运行.
	让我们看一个例子其中,我们想得到8个页:
	unsigned long page;
	page = __get_free_pages(GFP_KERNEL, 3);
	if (!page){
		/* 没有足够的内存:你必须处理这种错误! */
		return -ENOMEM;
	}
		
	/* page 现在指向8个连续页中第1页的地址 */
	在此我使用完成这8个页之后释放它们:
	free_pages(page, 3);

	/* 页现在已经被释放了,我们不该再访问
	 * 存放在"page"中地址了
	 */
		
	GFP_KERNEL参数是gfp_mask标志是一个例子.
	调用_get_free_pages()之后要注意进行错误检查.内核分配可能失败,因此你的代码必须
	进行检查并做相应处理.这意味在此之前,你所做的所有工作可能前功,甚至还需要回归到原来的状态
	下因为如此,在程序开始时先进行内存分配是很有意义的,这能让错误处理得容易一点.如果
	你不这么做,那么在你想要分配内存的时候如果失败了,局面可能就难以控制了
	当你需要以页为单位的一族连续物理页时,是在只需要一两页时,这些低级页函数很有用.对于
	常用的以字节为单位的分配来说,内核提供的函数是kmalloc()

12.4 kmalloc()
	kmalloc()函数与用户空间的malloc()一族函数非常类似,只不过它多了一个flags参数.
	kmalloc()函数是一个简单的接口,用它可以获得以字节为单位的一块内核内存.
	如果你需要整个页,那么前面讨论的页分配接口可能是更好的选择.但是对大多数据内核分配来说,kmalloc
	接口用得更多.
	kmalloc()在<linux/slab.h>中声明:
	void *kmalloc (size_t, gfp_t flags)
	if (!p)
		/* 处理错误 */
	如果kmalloc()调用成功,那么,ptr现在指向一个内存块,内存块的大小至少为所请求的大小.
	GFP_KERNEL标志表示在试图获取内存并返回给kamlloc()的调用者的过程中,内存分配器将要
	采取的行为.

12.4.1 gfp_mask标志
	我们已经看过几个例子,发现不管是在低级页分配函数中,还是在kmalloc()中都乃至了分配
	器标志.现在我们就深入讨论一下这些标志.
	这些标志可分为三类:行为修饰符,区修饰符及类型.行为修饰符表示内核应当如何分配所需
	的内存.在某些特定情况下,只能使用某些特定的方法分配内存

	例如,中断处理程序就要求内核在分配内存的过程中不能睡眠(因为中断处理程序不能被重新
			调度).区修改符表示从哪儿分配内存.

	前面我们,内核把物理内存分为多个区,每个区用于不同的目的.区修饰符指明到底从这些
	区中的哪一区中进行分配. 类型标志组合了行为修饰符和区修饰符,将各种可能用到的组合
	归纳为不同类型,简化了修饰符的使用;这样你只需指定一个标志就可以了.

	GFP_KERNEL就是一种类型标志,内核中进程上下文相关代码可以使用它.
	1.行为修饰符
	2.区修饰符
	3.类型标志

12.4.2 kfree()
	kfree()函数释放由kmalloc分配出来的内存块,如果想要释放内存不是由kmalloc()
	分配的,或者想要释放的内存释放了,.分配和回收要注意配对使用,以避免泄漏
	调用kfree(NULL)是安全的.

	让我们看一个在中断处理程序中分配内存的例子.在这个例子中,中断处理程序想分配
	一个缓冲区来保存输入数据.
	BUF_SIZE定义为以字节为单位的缓冲区长度,它该是大于两个字节的.

12.5 vmalloc()
	大多数情况下,只有硬件设备需要得到物理地址连续的内存.在很多体系结构上硬件设备
	存在于内存管理单元以外,它根本不理解什么是虚拟地址.因此,硬件设备用到的任何
	内存区都必须是物理上连续的地址,而不仅仅是虚拟地址连续的块.

	而供软件使用的内存块就可以使用只有虚拟地址连续的内存块.但是你在编程中,根本察觉
	不到这种差异.对内核而言,所有内存看起来都是逻辑上连续的.

	尽管在某些情况下才需要物理上连续的内存块,但是,很多内核代码都用kmalloc()
	获得内存而不是vmalloc ,这是因为性能问题
	void *vmalloc(unsigned long size)
	void vfree(const void *addr)
	这个函数会释放从addr开始的内存块,其中addr是以后由vmalloc()分配的内存块的地址.
	这个函数也可以睡眠,因此不能从中断上下文中调用.它没有返回值.
	这个函数用起来比较简单:

12.6 slab层
	slab分配器的概念首先在sun公司的sunOS 5.4操作系统中得以实现.Linux数据结构缓存层具
	有同样的名字和基本设计思想
	slab分器试图在几个基本原则之间寻求一种平衡:
	*频繁使用的数据结构也会频繁分配和释放,因此应当缓存它们.
	*频繁分配和回收必然会导致内存碎片,为了避免这种现象,空闲链表的缓存会连续地存放
	*回收的对象可以立即投入下一次分配,因此,对于频繁的分配和释放,空闲链表能够提高其
	性能.
	*如果分配器知道对象大小,页大小和总的高速缓存的大小这样的概念,它会做出更
	明智的决策.
	*如果让部分缓存专


12.6.1 每个高速缓存都使用kmem_cache结构来表示.这个结构包含三个链表:slabs_full
partial slabs_empty
 struct slab {
	 struct list_head list;
	 unsigned long colouroff;
	 void *s_mem;
	 unsigned int inuse;
	 kmem_bufctl_t free;
 };
	
static void *kmem_getpages(struct kmem_cache *cachep, gfp_t flags, int nodeid)
{

	
}

该函数使用__get_free_pages()来为高速缓存分配足够多的内存.该函数的第一个参数
就指向需要很多页的特定高速缓存.第二个参数是要传给__get_free_pages()的标志,注意
这个标志是如何与另一个值进行二进制"或"运算的,这相当于把高速缓存需要标志加到flags参数上.

分配的页的大小为2的幂次方,存放在cachep->gfporder中.由于分配器NUMA系统上提供了较好的
性能,但是访问节点之外的内存会导致性能的损失.为了便于理解,我们可以忽略与NUMA相关的代码
写一个简单的kmem_getpages()函数:
static inline void *kmem_getpages(struct kmem_cache *cachep, gfp_t flags)
{
	void *addr;
	flags |= cachep->gfpflags;
	addr = (void*) __get_free_pages(flags, cachep->gfporder);
	return addr;
}

	接着,调用kmem_freepages()释放内存,而对给定的高速缓存页,kmem_freepages()最终调用
	free_pages().
	
	当然,slab层的关键就是避免频繁分配和释放页.由此可知,slab层只有地当给定的高速缓存
	部分中既没有满也没有空的slab时,才会调用页分配函数.而只有在下列情况下才会释放函数.

12.6.2 slab分配器接口
	一个新的高速缓存通过以下函数创建:
	struct keme_cache *keme_cache_create(const char *name,
										 size_t size,
										 size_t align,
										 unsigned long flags,
										 void (*ctor)(void *));

salb分配器的使用实例,这个例子用的是task_struct
kernel/fork.c
	
	首先,内核用一个全局变量存放指向task_struct高速缓存的指针:
	struct kmem_cache *task_struct_cachep;
	在内核初始化期间,在定义于kernel/fork.c中fork_init()中会创建高速缓存
	task_struct_cachep = keme_cache_create("task_struct",
											sizeof(struct task_struct)
											ARCH_MIN_TASKALIGN,
											SLAB_PANIC | SLAB_NOTRACK,
											NULL)
	每当进程调用fork()时,一定会创建一个新的进程描述符(回忆一下第3章).
	这是在dup_task_struct()完成的,而该函数会被do_fork()调用:
	struct task_struct *tsk;

	tak = keme_cache_alloc(task_struct_cachep, GFP_KERNEL);
	if(!tsk)
		return NULL;

	进程执行完成后,如果没有子进程在等待的话,它的进程描述符就会被释放,并返回给
	task_struct_cachep slab高速缓存.这是在free_task_struct()中执行的
	kmem_cache_free(task_struct_cachep,tsk)

	由于进程描述符是内核的核心组成部分,时刻都要用到.因此高速缓存不会被撤销掉.
	int err;
	err = keme_cache_destory(task_struct_cachep);
	slab层负责内存紧缺情况下对底层的对齐,着色,分配,释放和回收等.


12.7 在栈上的静态分配

12.7.1 单页内核栈
12.7.2 在栈上光明正大地工作
					
12.8 高端内存映射
	在高端内存中的页不能永久地映射内核地址到空间上去.因此通过alloc_pages()
	以__GFP_HIGHMEM标志获得的页不可能有逻辑地址.
	在x86上,高效内存的页被映射到3-4GB

12.8.1 永久映射
	要映射一个给定的page结构到内核地址空间,可以使用定义在文件highmem.h中的这个
	函数:
	void *kmap(struct page *page)
	这个函数在高端内存或低端内存上都能用.如果page结构对应的是低端内存中的一页,
	函数只会单纯地返回该页的虚拟地址.如果页位于高端内存,则会建立一个永久映射,再
	返回地址.

	void kunmap(struct page *page)解除映射

12.8.2 临时映射
	当必须创建一个映射而当前的上下文又不能睡眠时,内核提供了临时映射.内核可以
	原子地把高端内存中的一个页映射到某个保保留的映射中,因此,临时映射
	可以用在不能睡眠的地方,比如中断处理程序中,因为获取时绝不会阻塞.
	通过下列函数建立一个临时映射:
	void *kmap_atomic(struct page *page, enum km_type type)
	参数是type是下列枚举类型之一,这些枚举描述了临时映射的目的.
	这个函数不会阻塞,因此可以用在中断上下方和其他不能重新调度的地方,它
	也禁止内核抢占,这是必要的.因为映射对每个处理器都是唯一
	通过下列函数取消映射:
	void kunmap_atomic(void *kvaddr, enum km_type type)
	这个函数也不会阻塞.在很多体系结构中,除非激活了内核抢占,否则
	kmap_atomic()

12.9 每个CPU的分配
	支持SMP的现代操作系统使用每个CPU上的数据,对于给定的处理器其数据是唯一的.
	一般来说,每个CPU的数据存放在一个数组中.数组中的第一项对应着系统上一个存在
	的处理器.按当前处理号确实这个数组的当前元素.
	unsigned long my_percpu[NR_CPUS]
	然后,按如下方式访问它:
	int cpu;
	cpu = get_cpu()
	my_percup[cpu]++
	put_cpu();

	注意,上面的代码并没有出现锁,这是因为所操作的数据对当前处理器来说是唯一的.

12.10 新的每个CPU接口
	2.6内核为了方便创建和操作每个CPU数据,而引进了新的操作接口,称作percpu,该接口
	归纳了前面所述的操作行为,简化了创建和操作每个cpu的数据.
	但我们讨论的创建和访问每个CPU的方法依然有效,不过大型对称多处理器计算机要求
	对每个cpu数据操作更简单,功能更强大,正是这种背景下,新接口应运而生.

12.10.1 编译时的每个CPU数据
	在编译时定义每个CPU变量易如反掌:
	DEFINE_PER_CPU(type, name);


12.10.2 运行时的每个CPU数据
	内核实现每个CPU数据的动态分配方法类似于kmalloc(),该例程为系统上的每个处理器创建
	所需内存的实例


12.11 使用每个CPU数据的原因
	使用每个CPU数据具有不少好处,首先是减少数据锁定.因为按照每个处理器访问每个CPU数据逻辑,
	你可以不再需要任何锁.你需要确保本地处理器只会访问它自己的唯一数据.
	系统本身并不存在任何措施禁止你从事欺骗活动.

	第二个好处是使用每个CPU数据可以大大减少缓存失效.
	综上所述,使用每个cpu数据会省去许多数据上锁,它唯一的安全要求就是禁止内核抢占.

12.12 分配函数的选择
	在这么多分配函数和方法中,有时并不能搞清楚到底该选择那种方式分配----但是这确实很重要
	如果你需要连续的物理页,就可以使用某个低级页分配器或kmalloc.这是内核中内存分配常用的
	方式,传递给这些函数的两个最常用标志是GFP_ATOMIC和GFP_KERNEL
	GFP_ATOMIC 表示进行不睡眠的高优先级分配,这是中断处理程序和其他不能睡眠的代码段的需要.
	对于可以睡眠的代码,则应该使用GFP_KERNEL获取所需内存.

	如果你想从高端内存进行分配,就使用alloc_pages().alloc_pages()函数返回一个指向struct
	page结构的指针,而不是一个指向某个逻辑地址的指针.因为高端内存很可能并没有被映射,
	因此,访问它的唯一方式就是通过相应的struct page结构.为了获得真正的指针,应该调用kmap
	把高端内存映射到内核的逻辑地址空间.

	如果不需要物理上连续的页,仅仅需要虚拟地址上连续的页,可以使用vmalloc

	如果你要创建和撤销很多大的数据结构,那么考虑建立slab高速缓存.slab层会给每个处理器
	维持一个对象高速缓存(空闲链表),这种高速缓存会极大地提高对象分配和回收性能.slab
	层不是频繁地分配和释放缓存,而是为你把事先分配好的对象放到缓存中.当你需要一块新的
	内存来存放数据时,slab层一般无须另外去分配内存,你只需要从高速缓存中得到一个对象就
	可以了.

12.13 小结
	本意中,我们学习了Linux内核如何管理内存.我们首先看到了内存空间的各种不同的描述单位,包括
	字节,页面和区.我们接着讨论了各种内存分配机制,其中包括页分配器和slab分配器

	分配过程中不得堵塞,或者访问文件系统等约束.为此我们讨论了gfp标志以及每个标识的针对场景.
	分配内存相对复杂是内核开发和用户程序开发的最大区别之一,本章使用大量篇幅描述内存分配的
	各种不同接口----通过这些不同调用接口,在本章基础上,我们讨论了虚拟文件系统VFS
	--负责管理文件系统且为用户空间程序提供了一致性接口的内核子系统,我们继续深入!








	









